{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764be0ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "#import sys\n",
    "#sys.path.append('..')\n",
    "#from autocrop import crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5c62b112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def crop(path=None):\n",
    "    \"\"\"\n",
    "    Returns a cropped version of the image with the path path.\n",
    "\n",
    "    Parameters:\n",
    "    - path: path to the image being cropped\n",
    "\n",
    "    Returns:\n",
    "    - cropped: image which is the cropped version of the image with the path\n",
    "               path\n",
    "    \"\"\"\n",
    "    assert type(path) == str, 'The path should be in string format!'\n",
    "    \n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    assert np.sum(img) != None, 'the path is not right or there is no such a file. Check path or file name.'\n",
    "    assert img.shape[0:3] != None, 'The image is not in right format. Image should have three diamensions'\n",
    "\n",
    "    # leave only green color\n",
    "    img[:, :, 0] = 0\n",
    "    img[:, :, 2] = 0\n",
    "\n",
    "    # convert to gray scale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # more contrast between foreground and background\n",
    "    contrasted_img = apply_contrast(gray_img)\n",
    "\n",
    "    # erode image\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    eroded_img = cv2.erode(contrasted_img, kernel, iterations=15)\n",
    "\n",
    "    # located contours\n",
    "    contours = _locate_contours(eroded_img)\n",
    "\n",
    "    img_contours = np.zeros(img.shape)\n",
    "    cv2.drawContours(img_contours, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "    # determine cropped image based on contours\n",
    "    crop_box = _determine_cropped_image_box(img, contours)\n",
    "\n",
    "    # crop the original image\n",
    "    cropped = img[crop_box[1]:crop_box[3], crop_box[0]:crop_box[2]]\n",
    "\n",
    "    return cropped\n",
    "\n",
    "\n",
    "def apply_contrast(img):\n",
    "    \"\"\"\n",
    "    Returns a contrasted version of img.\n",
    "\n",
    "    Returns:\n",
    "    - contrasted_img: contrasted version of img\n",
    "    \"\"\"\n",
    "\n",
    "    contrast_threshold = 2\n",
    "    grid_size = 2\n",
    "    alpha = 3  # (1.0-3.0)\n",
    "    beta = 0  # (0-100)\n",
    "\n",
    "    # CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=contrast_threshold,\n",
    "                            tileGridSize=(grid_size, grid_size))\n",
    "    clahe_img = clahe.apply(img)\n",
    "\n",
    "    adjusted = cv2.convertScaleAbs(clahe_img, alpha=alpha, beta=beta)\n",
    "\n",
    "    return adjusted\n",
    "\n",
    "\n",
    "def _locate_contours(img):\n",
    "    \"\"\"\n",
    "    Returns the substantial contours in img.\n",
    "\n",
    "    Parameters:\n",
    "    - img: the image being analyzed\n",
    "\n",
    "    Returns:\n",
    "    - substantial_contours: the substantial contours in img\n",
    "    \"\"\"\n",
    "\n",
    "    min_threshold = 75\n",
    "    threshold_output = 255\n",
    "    min_countour_area = 15000\n",
    "\n",
    "    _, threshold = cv2.threshold(img, min_threshold,\n",
    "                                 threshold_output,\n",
    "                                 cv2.THRESH_BINARY)\n",
    "\n",
    "    # dilated = cv2.morphologyEx(threshold, cv2.MORPH_OPEN,\n",
    "    #                            cv2.getStructuringElement(cv2.MORPH_ELLIPSE,\n",
    "    #                            (10, 10)))\n",
    "\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_LIST,\n",
    "                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    substantial_contours = []\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > min_countour_area:\n",
    "            substantial_contours.append(contour)\n",
    "\n",
    "    cv2.drawContours(img, contours, -1, (0, 255, 0), 3)\n",
    "\n",
    "    return substantial_contours\n",
    "\n",
    "\n",
    "def _determine_cropped_image_box(img, contours):\n",
    "    \"\"\"\n",
    "    Returns the pixel box including all contours in contours.\n",
    "\n",
    "    Parameters:\n",
    "    - img: the image being analyzed\n",
    "    - contours: a list of countours thats locations should be included in the\n",
    "                outputted box size\n",
    "\n",
    "    Returns:\n",
    "    - crop_box: the pixel box including all contours in contours in form [left,\n",
    "                top, right, bottom]\n",
    "    \"\"\"\n",
    "    # https://stackoverflow.com/questions/37803903/opencv-and-python-for-auto-cropping\n",
    "    crop_box = [-1, -1, -1, -1]\n",
    "    for contour in contours:\n",
    "        contour_x, contour_y, contour_w, contour_h = cv2.boundingRect(contour)\n",
    "        if crop_box[0] < 0:\n",
    "            crop_box = [contour_x, contour_y, contour_x + contour_w,\n",
    "                        contour_y + contour_h]\n",
    "        elif contour_x > np.shape(img)[0] / 2:\n",
    "            crop_box[0] = min(contour_x, crop_box[0])\n",
    "            crop_box[1] = min(contour_y, crop_box[1])\n",
    "            crop_box[2] = max(contour_x + contour_w, crop_box[2])\n",
    "            crop_box[3] = max(contour_y + contour_h, crop_box[3])\n",
    "    \n",
    "    # add bounding space\n",
    "    crop_box[0] = max(0, crop_box[0] - 50)\n",
    "    crop_box[1] = max(0, crop_box[1] - 50)\n",
    "    crop_box[2] = min(np.shape(img)[0], crop_box[2] + 100)\n",
    "    crop_box[3] = min(np.shape(img)[1], crop_box[3] + 100)\n",
    "\n",
    "    return crop_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bed9c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('test_image.jpg') == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da18b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath = 'test_image1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aaa76fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The path should be in string format!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2014/44903529.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2014/826047072.py\u001b[0m in \u001b[0;36mcrop\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     14\u001b[0m                \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \"\"\"\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The path should be in string format!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The path should be in string format!"
     ]
    }
   ],
   "source": [
    "dat = crop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725c320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb05b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cdeabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = crop('test_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ea98ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert object of type 'list' to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2014/382674992.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Can't convert object of type 'list' to 'str' for 'filename'"
     ]
    }
   ],
   "source": [
    "img = cv2.imread([[1],[1],[1]], cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5178de76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21944668\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2de3436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.any == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f465b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(859, 861, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e635f6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape[0:3] != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e80df218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img != None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956297f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
